# -*- coding: utf-8 -*-
"""model_lernv1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iJ3yAR9O9gt64AwzYecMIGpEe70XxDB5
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.regularizers import l2
from tensorflow.keras.optimizers import Adam
from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

# Load the data from Google Drive
file_path = '/content/drive/My Drive/summerschool/data_modv6.csv'

data = pd.read_csv(file_path, sep=',')  # Assuming the file is tab-separated, adjust accordingly

# Identify numerical and categorical columns
numerical_cols = data.select_dtypes(include=['int64', 'float64']).columns.tolist()
categorical_cols = data.select_dtypes(include=['object']).columns.tolist()

# Remove target columns from feature columns lists
numerical_cols.remove('home_club_goals')
numerical_cols.remove('away_club_goals')

# Preprocessing for numerical data
numerical_transformer = Pipeline(steps=[
    ('scaler', StandardScaler())
])

# Preprocessing for categorical data
categorical_transformer = Pipeline(steps=[
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

# Bundle preprocessing for numerical and categorical data
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_cols),
        ('cat', categorical_transformer, categorical_cols)
    ])

# Prepare features and target variables
X = data.drop(columns=['home_club_goals', 'away_club_goals'])
y = data[['home_club_goals', 'away_club_goals']]

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Preprocess the data
X_train = preprocessor.fit_transform(X_train).toarray()
X_test = preprocessor.transform(X_test).toarray()

# Define the neural network model
model = Sequential()
model.add(Dense(512, input_dim=X_train.shape[1], activation='relu', kernel_regularizer=l2(0.001)))
model.add(Dropout(0.3))
model.add(Dense(256, activation='relu', kernel_regularizer=l2(0.001)))
model.add(Dropout(0.3))
model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))
model.add(Dropout(0.3))
model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))
model.add(Dropout(0.3))
model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.001)))
model.add(Dense(2, dtype='float32'))  # Output layer for home and away goals

# Compile the model with a different learning rate
optimizer = Adam(learning_rate=0.0001)
model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])

# Define early stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)

# Train the model
history = model.fit(X_train, y_train, epochs=100, batch_size=256, validation_split=0.2, callbacks=[early_stopping])

# Evaluate the model
loss, mae = model.evaluate(X_test, y_test)
print(f'Mean Absolute Error: {mae}')

# Predict
y_pred = model.predict(X_test)

"""
# Round the predictions to the nearest whole number
y_pred_rounded = np.round(y_pred)
"""

def evaluate_predictions(true_results, predicted_results):
    correct_wins = 0
    correct_losses = 0
    correct_draws = 0
    total_wins = 0
    total_losses = 0
    total_draws = 0

    for i in range(len(true_results)):
        true_home, true_away = true_results[i]
        pred_home, pred_away = predicted_results[i]

        true_outcome = 'win' if true_home > true_away else 'loss' if true_home < true_away else 'draw'
        pred_outcome = 'win' if pred_home > pred_away else 'loss' if pred_home < pred_away else 'draw'

        if true_outcome == 'win':
            total_wins += 1
            if true_outcome == pred_outcome:
                correct_wins += 1
        elif true_outcome == 'loss':
            total_losses += 1
            if true_outcome == pred_outcome:
                correct_losses += 1
        elif true_outcome == 'draw':
            total_draws += 1
            if true_outcome == pred_outcome:
                correct_draws += 1

    total_correct = correct_wins + correct_losses + correct_draws
    total_predictions = len(true_results)

    # Calculate percentages
    win_accuracy = (correct_wins / total_wins) * 100 if total_wins > 0 else 0
    loss_accuracy = (correct_losses / total_losses) * 100 if total_losses > 0 else 0
    draw_accuracy = (correct_draws / total_draws) * 100 if total_draws > 0 else 0
    overall_accuracy = (total_correct / total_predictions) * 100

    return win_accuracy, loss_accuracy, draw_accuracy, overall_accuracy

# Evaluate without rounding
win_accuracy, loss_accuracy, draw_accuracy, overall_accuracy = evaluate_predictions(y_test.values, y_pred)
print(f'Without Rounding:')
print(f'Correct Wins: {win_accuracy:.2f}%')
print(f'Correct Losses: {loss_accuracy:.2f}%')
print(f'Correct Draws: {draw_accuracy:.2f}%')
print(f'Overall Correct Predictions: {overall_accuracy:.2f}%')

"""
# Evaluate with rounding
win_accuracy, loss_accuracy, draw_accuracy, overall_accuracy = evaluate_predictions(y_test.values, y_pred_rounded)
print(f'\nWith Rounding:')
print(f'Correct Wins: {win_accuracy:.2f}%')
print(f'Correct Losses: {loss_accuracy:.2f}%')
print(f'Correct Draws: {draw_accuracy:.2f}%')
print(f'Overall Correct Predictions: {overall_accuracy:.2f}%')
"""